---
title: "Problem 3.1"
author: "Chen Bo Calvin Zhang"
date: "19/10/2020"
output:
  pdf_document: default
  html_document: default
---

We want to use an example to check that the mean and variance obtained after applying the Mahalanobis transformation is consistent with the results we have obtained in the notes. In particular we want to check that

$$E(\boldsymbol{x}) = \boldsymbol{\mu} \text{ and } Var(\boldsymbol{x}) = \boldsymbol{\Sigma} \implies E(\boldsymbol{y}) = \boldsymbol{0} \text{ and } Var(\boldsymbol{y}) = \boldsymbol{I}$$

where

$$\boldsymbol{y} = \boldsymbol{\Sigma}^{-\frac{1}{2}} (\boldsymbol{x} - \boldsymbol{\mu})$$

is the Mahalanobis transformation on a vector $\boldsymbol{x}$.

Firstly, let us create the data matrix 

$$\boldsymbol{X} = \begin{pmatrix} 4 & 3 \\ -1 & 3 \\ 3 & 5 \end{pmatrix}$$

```{r, echo=TRUE}
X = matrix(c(4, -1, 3, 1, 3, 5), ncol=2)
print(X)
```

Now compute the column means and covariance matrix.

```{r, echo=TRUE}
mu = colMeans(X)
print(mu)
Sigma = cov(X)
print(Sigma)
```

In matrix notation, we can write

$$\boldsymbol{Y} = \boldsymbol{C_nX\Sigma^{-\frac{1}{2}}}$$

where $\boldsymbol{C_n}$ is the centering matrix.

Now, let us find the inverse square root of $\boldsymbol{\Sigma}$ using the eigenvalue decomposition.

```{r, echo=TRUE}
eigen = eigen(Sigma)
lambda = eigen$values
print(lambda)
U = eigen$vectors
print(U)

inv_sqrt_Sigma = U %*% diag(lambda^(-1/2)) %*% t(U)
print(inv_sqrt_Sigma)
```

Finally, compute the Mahalanobis transformation and check that the column means and the covariance matrix are as expected.

```{r, echo=TRUE}
# sweep() function used to centre the matrix X, 2 means that we are working column-wise
Y = sweep(X, 2, mu) %*% inv_sqrt_Sigma
print(Y)

# check that E(Y) = 0 matrix and Var(Y) = I
print(colMeans(Y))
print(cov(Y))
```

As we can see, the mean is very close to zero for both columns and the covariance matrix is the identity matrix. The difference is due to floating point approximation.